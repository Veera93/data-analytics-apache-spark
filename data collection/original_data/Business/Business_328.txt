 SHANGHAI — Civil society groups in Myanmar on Thursday criticized Facebook’s chief executive, Mark Zuckerberg, arguing that he mischaracterized his company’s effectiveness at detecting and quashing messages encouraging violence in the country. Taking aim at comments Mr. Zuckerberg made in a recent interview, the groups said that Facebook had no consistent methods for dealing with hate speech in Myanmar. The same problems keep recurring, they said, with the company routinely failing to follow up on their comments and suggestions. In a conversation with Ezra Klein of Vox this week, Mr. Zuckerberg referred to a pair of chain letters that were widely shared in Myanmar on Facebook Messenger last year. One message warned Buddhist groups about an imminent attack by Muslims, expected on Sept. 11. The other, spread among Muslims, cautioned of violence from Buddhist nationalists on the same date. “So that’s the kind of thing where I think it is clear that people were trying to use our tools in order to incite real harm,” Mr. Zuckerberg said. “Now, in that case, our systems detect that that’s going on. We stop those messages from going through.” In an open letter, the organizations, which have worked with Facebook to flag dangerous and misleading content, including the chain letters, said the messages had spread for days, caused widespread fear and set off at least three violent incidents. They also said there was no system at all, only a group of organizations and volunteers doing their best to keep up with a torrent of vitriol. “In your interview, you refer to your detection ‘systems.’ We believe your system, in this case, was us — and we were far from systematic,” the letter says. “From where we stand, this case exemplifies the very opposite of effective moderation: It reveals an overreliance on third parties, a lack of a proper mechanism for emergency escalation, a reticence to engage local stakeholders around systemic solutions and a lack of transparency.” Facebook responded to the criticism in a satement on Friday. “We are sorry that Mark did not make clearer that it was the civil society groups in Myanmar who first reported these messages,” it said. “We took their reports very seriously and immediately investigated ways to help prevent the spread of this content. We should have been faster, and are working hard to improve our technology and tools to detect and prevent abusive, hateful or false content.” Myanmar highlights existential questions about Facebook’s mission and responsibilities. The site has closely connected people in the country — in many cases, Facebook is the only online service they use. It has also become a major channel for the spread of hate speech and propaganda that has encouraged and obfuscated ethnic cleansing of the country’s Muslim Rohingya, according to human rights groups. Almost 700,000 Rohingya have fled to neighboring Bangladesh since last summer, when the military started a crackdown in the country’s western Rakhine State. Last month, United Nations investigators said Facebook played a role in spreading hate speech that incited violence against the Rohingya. For Mr. Zuckerberg, the timing of the letter is bad. Both he and his top deputy, Sheryl Sandberg, are making multiple media appearances this week to address questions about how the company handles users’ personal data. The company has faced harsh criticism for reports on how information about millions of users may have been improperly leaked to a political consulting firm connected to President Trump’s 2016 campaign. The criticism has sent the company’s stock tumbling. Next week, Mr. Zuckerberg is expected to appear at multiple congressional hearings. Among the half-dozen signatories of the letter posted on Thursday in Myanmar are Phandeeyar, a leading technology hub in the country that helped Facebook draft its Burmese-language community standards; Myanmar ICT for Development Organization, which monitors online hate speech; and the Center for Social Integrity. The letter lists what the groups say are several problems with Facebook. It says the company lacks adequate tools to report messages that might incite violence. It also says Facebook failed to provide channels for organizations to communicate with data and engineering employees who might have been able to devise solutions to the problems. “Presumably, your data team should be able to trace the original sources of flagged messages and posts and identify repeat offenders, using these insights to inform your moderation and sanctioning,” the letter says. Jes Petersen, chief executive of Phandeeyar, said problematic messages in Myanmar were not a one-time problem. “There’s multiple cases of similar things that have happened where we’ve done everything we can to bring it to Facebook’s attention but we don’t see much happening on their end,” he said. “That’s a big part of the problem.” Victoire Rio, a social media analyst in the country who previously worked at Phandeeyar, said another major issue was Facebook’s lack of Burmese speakers for local monitors to communicate directly with. “It’s evident to us that there are not enough resources and not enough human resources dedicated to Myanmar,” Ms. Rio said. She added that the company’s Burmese-speaking reviewers were based in Dublin, and from the company’s recruiting pages it seems it is struggling to find qualified candidates. The groups also faulted Facebook’s lack of transparency. They said that after they had reported the messages that Mr. Zuckerberg cited in his interview, they heard nothing from the company about what happened or how Facebook would better respond. “I was seriously concerned and looking for anyone I could,” Ms. Rio said. “I was surprised to hear that Mark had been contacted about this fairly quickly, the use of strong language was effective.”