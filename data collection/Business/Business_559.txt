 Perhaps at some point in the past few years you’ve told Facebook that you like, say, Kim Kardashian West. When you hit the thumbs-up button on her page, you probably did it because you wanted to see the reality TV star’s posts in your news feed. Maybe you realized that marketers could target advertisements to you based on your interest in her. What you probably missed is that researchers had figured out how to tie your interest in Ms. Kardashian West to certain personality traits, such as how extroverted you are (very), how conscientious (more than most) and how open-minded (only somewhat). And when your fondness for Ms. Kardashian West is combined with other interests you’ve indicated on Facebook, researchers believe their algorithms can predict the nuances of your political views with better accuracy than your loved ones. As The New York Times reported on Saturday, that is what motivated the consulting firm Cambridge Analytica to collect data from more than 50 million Facebook users, without their consent, to build its own behavioral models to target potential voters in various political campaigns. The company has worked for a political action committee started by John R. Bolton, who served in the George W. Bush administration, as well as for President Trump’s presidential campaign in 2016. “We find your voters and move them to action,” the firm boasts on its website. Cambridge Analytica now says it has destroyed the user data it collected on Facebook. Raw data reviewed by The Times suggests the information, or copies of it, may still exist. In either case, specific user information was merely a means to an end, a building block in a far more ambitious construction: a behavioral model powerful enough to manipulate people’s activity and, potentially, sway elections. The firm adapted its approach to personality modeling from studies conducted by researchers at Stanford University and the Psychometrics Center at the University of Cambridge. The studies relied on data collected by a Facebook app called myPersonality, a 100-question quiz developed by the Psychometrics Center that assessed a person’s openness, conscientiousness, extroversion, agreeableness and neuroticism, traits commonly referred to in the academic community by the acronym Ocean. Many respondents who took the quiz through the myPersonality app authorized it to gain access to their Facebook profile data, and information about their friend network — access that was allowed by the social network at the time. That allowed researchers to cross-reference the results of the quiz — numeric Ocean scores — with the users’ Facebook “likes,” and build a model from the correlations they found between the two. With that model, the researchers could often make precise guesses about subsequent users’ personalities using only a list of their likes, no 100-question quiz necessary. One of the studies the Psychometrics Center produced, published in 2015 in the Proceedings of the National Academy of Sciences, was built on the “likes” and Ocean scores of more than 70,000 respondents who took the myPersonality quiz on Facebook. It found that a person who liked the movie “Fight Club,” for example, was far more likely to be open to new experiences than a person who liked “American Idol,” according to a review of data provided to The Times by Michal Kosinski, an author of the 2015 study and a professor of organizational behavior at Stanford. In that study, the researchers compared the accuracy of their model with personality assessments made by the respondents’ friends. The friends were given a 10-question version of the myPersonality quiz and asked to answer based on their knowledge of the respondents’ personalities. Based on a sample of more than 32,000 participants who were assessed by both the model and one or two friends, the researchers found that the model, using just 10 likes, was more accurate than a work colleague. With 70 likes, it was more accurate than a friend or roommate; with 150, more accurate than a family member; and with 300, more accurate than a spouse. The model, the researchers said, was particularly adept at “predicting life outcomes such as substance use, political attitudes and physical health.” The real-world efficacy of the approach, however, has been called into question. When Cambridge Analytica approached the Psychometrics Center about using its models, the center declined. Cambridge Analytica then turned to Aleksandr Kogan, a psychology professor at Cambridge University who was familiar with the center’s work. Dr. Kogan developed a Facebook app called “thisisyourdigitallife,” a quiz similar to myPersonality, and used it to harvest data from more than 50 million Facebook profiles. Of those, 30 million contained enough information to generate personality profiles. Only 270,000 users authorized Dr. Kogan’s app to have access to their data, and all were told that their information was being used for academic research. Cambridge then pitched its services to potential political and commercial clients, ranging from Mastercard and the New York Yankees to the Joint Chiefs of Staff. Facebook has now banned Cambridge Analytica from its platform, as well as its parent company and Dr. Kogan. In Facebook’s eyes, Dr. Kogan’s infraction was not collecting the data, but giving it to Cambridge Analytica. “Although Kogan gained access to this information in a legitimate way and through the proper channels that governed all developers on Facebook at that time, he did not subsequently abide by our rules,” Facebook’s deputy general counsel said in a statement on Friday. By handing over that information to a private company, Facebook said, Dr. Kogan violated its terms of service. Facebook in 2015 changed its policies, including altering rules about how third-party apps can gain access to information about users’ friends. But user data collected through such apps over the years probably remains in the wild, not to mention the models that can continue to be used to target people around the world.